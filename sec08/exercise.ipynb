{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "782555a7-6254-4b42-b251-fe76f85d28e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6d01d63-1714-458c-8c52-66bcf3710d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']\n",
    "\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    '.', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n",
    "\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    '.', train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n",
    "\n",
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label])\n",
    "          for img, label in cifar10\n",
    "          if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f418b98-147d-4ffa-a7bc-290855b1a2c9",
   "metadata": {},
   "source": [
    "# 1. Kernerl_size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff89231-68b7-4a70-8c51-efeafd2c2eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5 // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c68f08-04bf-47bd-b99a-71647ba54515",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv1 = nn.Conv2d(3, 16, self.kernel_size, padding=self.kernel_size // 2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, self.kernel_size, padding=self.kernel_size // 2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    device = ( torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "    for epoch in range(1, n_epochs + 1):  \n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:  \n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            outputs = model(imgs) \n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()  \n",
    "            loss.backward()  \n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))\n",
    "            \n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  \n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) \n",
    "                total += labels.shape[0] \n",
    "                correct += int((predicted == labels).sum()) \n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fead6032-8b1a-47ed-83d4-9de1c407154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9bbc30-769d-4b4d-8fb0-13448e404974",
   "metadata": {},
   "source": [
    "### the number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "794b495d-79ae-422e-9561-862631530dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My device is cuda\n",
      "kernel_size = 3 : [432, 16, 1152, 8, 16384, 32, 64, 2] sum : 18090\n",
      "kernel_size = 5 : [1200, 16, 3200, 8, 16384, 32, 64, 2] sum : 20906\n"
     ]
    }
   ],
   "source": [
    "device = ( torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f'My device is {device}')\n",
    "\n",
    "Net_conv3 = Net(3).to(device=device)\n",
    "Net_conv5 = Net(5).to(device=device)\n",
    "\n",
    "numel_list3 = [p.numel() for p in Net_conv3.parameters()]\n",
    "print(f'kernel_size = 3 : {numel_list3} sum : {sum(numel_list3)}')\n",
    "\n",
    "numel_list5 = [p.numel() for p in Net_conv5.parameters()]\n",
    "print(f'kernel_size = 5 : {numel_list5} sum : {sum(numel_list5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a41e4da-959e-4dd0-83ee-681c86c3fbb5",
   "metadata": {},
   "source": [
    "### kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d7a6195-f8c2-4cf1-b6ec-d48730dfd127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/takakiyuto/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-15 14:34:53.425001 Epoch 1, Training loss 0.5798977567891407\n",
      "2021-09-15 14:34:55.671588 Epoch 10, Training loss 0.33098394399995257\n",
      "2021-09-15 14:34:58.177785 Epoch 20, Training loss 0.29061039712778325\n",
      "2021-09-15 14:35:00.681818 Epoch 30, Training loss 0.2666620386254256\n",
      "2021-09-15 14:35:03.191580 Epoch 40, Training loss 0.2483056040516325\n",
      "2021-09-15 14:35:05.695692 Epoch 50, Training loss 0.23055490476500456\n",
      "2021-09-15 14:35:08.206986 Epoch 60, Training loss 0.21382714565961983\n",
      "2021-09-15 14:35:10.712608 Epoch 70, Training loss 0.19941808980931142\n",
      "2021-09-15 14:35:13.224687 Epoch 80, Training loss 0.18296448708434773\n",
      "2021-09-15 14:35:15.705480 Epoch 90, Training loss 0.16896311440475428\n",
      "2021-09-15 14:35:18.194209 Epoch 100, Training loss 0.15702229638578027\n",
      "Accuracy train: 0.94\n",
      "Accuracy val: 0.89\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "optimizer = optim.SGD(Net_conv3.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(n_epochs, optimizer, Net_conv3, loss_fn, train_loader)\n",
    "validate(Net_conv3, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d3ca86e-b221-4a10-bf6c-3c7b42a60bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-15 14:35:18.566027 Epoch 1, Training loss 0.5596386515031195\n",
      "2021-09-15 14:35:20.925270 Epoch 10, Training loss 0.3280355742402897\n",
      "2021-09-15 14:35:23.546714 Epoch 20, Training loss 0.282826970859318\n",
      "2021-09-15 14:35:26.171057 Epoch 30, Training loss 0.25223569230289217\n",
      "2021-09-15 14:35:28.802554 Epoch 40, Training loss 0.22613409209023616\n",
      "2021-09-15 14:35:31.429111 Epoch 50, Training loss 0.20112430384963942\n",
      "2021-09-15 14:35:34.058080 Epoch 60, Training loss 0.18068940676511472\n",
      "2021-09-15 14:35:36.681772 Epoch 70, Training loss 0.1599704822537246\n",
      "2021-09-15 14:35:39.314108 Epoch 80, Training loss 0.14135940394299046\n",
      "2021-09-15 14:35:41.938980 Epoch 90, Training loss 0.1240192436298747\n",
      "2021-09-15 14:35:44.561144 Epoch 100, Training loss 0.10829334141342503\n",
      "Accuracy train: 0.97\n",
      "Accuracy val: 0.88\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "optimizer = optim.SGD(Net_conv5.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(n_epochs, optimizer, Net_conv5, loss_fn, train_loader)\n",
    "validate(Net_conv5, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5887a9-c9e1-4907-8386-0d30eff53922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
